{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":90104,"databundleVersionId":10442603,"sourceType":"competition"}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Let`s begin!","metadata":{}},{"cell_type":"markdown","source":"At first, to get things going, we need to import all the libraries we will use:","metadata":{}},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, models\nfrom transformers import BertTokenizer, BertModel\nimport torch.nn as nn\nimport torch.optim as optim\nfrom sklearn.metrics import cohen_kappa_score\nimport optuna","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.589233Z","iopub.execute_input":"2024-12-23T17:22:21.589544Z","iopub.status.idle":"2024-12-23T17:22:21.595088Z","shell.execute_reply.started":"2024-12-23T17:22:21.589521Z","shell.execute_reply":"2024-12-23T17:22:21.593734Z"},"trusted":true},"outputs":[],"execution_count":80},{"cell_type":"markdown","source":"To exclude the randomness in computing, we use the random_seed parameter:","metadata":{}},{"cell_type":"code","source":"random_seed = 42\nnp.random.seed(random_seed)\ntorch.manual_seed(random_seed)\ntorch.cuda.manual_seed_all(random_seed)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.596190Z","iopub.execute_input":"2024-12-23T17:22:21.596479Z","iopub.status.idle":"2024-12-23T17:22:21.613262Z","shell.execute_reply.started":"2024-12-23T17:22:21.596457Z","shell.execute_reply":"2024-12-23T17:22:21.612416Z"},"trusted":true},"outputs":[],"execution_count":81},{"cell_type":"markdown","source":"Let`s determine input and output paths and device we will work on:","metadata":{}},{"cell_type":"code","source":"train_csv = \"/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-12/train.csv\"\ntest_csv = \"/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-12/test.csv\"\nimages_dir = \"/kaggle/input/deep-learning-for-computer-vision-and-nlp-2024-12/images\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.614778Z","iopub.execute_input":"2024-12-23T17:22:21.615043Z","iopub.status.idle":"2024-12-23T17:22:21.627529Z","shell.execute_reply.started":"2024-12-23T17:22:21.615025Z","shell.execute_reply":"2024-12-23T17:22:21.626730Z"},"trusted":true},"outputs":[],"execution_count":82},{"cell_type":"markdown","source":"Creating dataframes and filling all NA values in \"Description\" feature:","metadata":{}},{"cell_type":"code","source":"# Read data\ntrain_df = pd.read_csv(train_csv)\ntest_df = pd.read_csv(test_csv)\n\n# Fill missing descriptions\ntrain_df['Description'].fillna('', inplace=True)\ntest_df['Description'].fillna('', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.628747Z","iopub.execute_input":"2024-12-23T17:22:21.628995Z","iopub.status.idle":"2024-12-23T17:22:21.695276Z","shell.execute_reply.started":"2024-12-23T17:22:21.628975Z","shell.execute_reply":"2024-12-23T17:22:21.694306Z"},"trusted":true},"outputs":[],"execution_count":83},{"cell_type":"markdown","source":"## Data processing","metadata":{}},{"cell_type":"markdown","source":"Let`s use resampling to balance the dataset:","metadata":{}},{"cell_type":"code","source":"# Balance the dataset by resampling\nclass_counts = train_df['AdoptionSpeed'].value_counts()\nmax_count = class_counts.max()\n\nbalanced_train_df = pd.concat([\n    train_df[train_df['AdoptionSpeed'] == cls].sample(max_count, replace=True, random_state=random_seed)\n    for cls in class_counts.index\n]).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.696288Z","iopub.execute_input":"2024-12-23T17:22:21.696609Z","iopub.status.idle":"2024-12-23T17:22:21.710775Z","shell.execute_reply.started":"2024-12-23T17:22:21.696585Z","shell.execute_reply":"2024-12-23T17:22:21.710140Z"},"trusted":true},"outputs":[],"execution_count":84},{"cell_type":"markdown","source":"As tokenizer we are going to use BERT:","metadata":{}},{"cell_type":"code","source":"# Tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.711561Z","iopub.execute_input":"2024-12-23T17:22:21.711906Z","iopub.status.idle":"2024-12-23T17:22:21.887926Z","shell.execute_reply.started":"2024-12-23T17:22:21.711848Z","shell.execute_reply":"2024-12-23T17:22:21.886876Z"},"trusted":true},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":85},{"cell_type":"markdown","source":"Let`s create a Dataset class we will work with:","metadata":{}},{"cell_type":"code","source":"class PetDataset(Dataset):\n    def __init__(self, dataframe, images_dir, tokenizer, max_text_length=128, transform=None):\n        self.dataframe = dataframe\n        self.images_dir = images_dir\n        self.tokenizer = tokenizer\n        self.max_text_length = max_text_length\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        row = self.dataframe.iloc[idx]\n        pet_id = row['PetID']\n        description = row['Description']\n        label = row.get('AdoptionSpeed', -1)\n\n        # Tokenize text\n        text_inputs = self.tokenizer(\n            description,\n            max_length=self.max_text_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors=\"pt\"\n        )\n\n        # Process images\n        image_files = [f for f in os.listdir(self.images_dir) if f.startswith(pet_id)]\n        images = []\n        for image_file in image_files:\n            image_path = os.path.join(self.images_dir, image_file)\n            image = Image.open(image_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            images.append(image)\n\n        if len(images) == 0:\n            images = [torch.zeros(3, 224, 224)]  # Default empty image tensor\n\n        images = torch.stack(images[:4])  # Take up to 4 images per ID\n\n        return {\n            'pet_id': pet_id,\n            'text_inputs': {key: val.squeeze(0) for key, val in text_inputs.items()},\n            'images': images,\n            'label': torch.tensor(label, dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.888929Z","iopub.execute_input":"2024-12-23T17:22:21.889167Z","iopub.status.idle":"2024-12-23T17:22:21.896657Z","shell.execute_reply.started":"2024-12-23T17:22:21.889135Z","shell.execute_reply":"2024-12-23T17:22:21.895793Z"},"trusted":true},"outputs":[],"execution_count":86},{"cell_type":"markdown","source":"collate_fn function:","metadata":{}},{"cell_type":"code","source":"def custom_collate_fn(batch):\n    text_inputs = {\n        'input_ids': torch.stack([item['text_inputs']['input_ids'] for item in batch]),\n        'attention_mask': torch.stack([item['text_inputs']['attention_mask'] for item in batch])\n    }\n\n    max_images = max([item['images'].size(0) for item in batch])\n    images = torch.stack([\n        torch.cat([item['images'], torch.zeros(max_images - item['images'].size(0), 3, 224, 224)])\n        if item['images'].size(0) < max_images else item['images']\n        for item in batch\n    ])\n\n    labels = torch.stack([item['label'] for item in batch])\n    pet_ids = [item['pet_id'] for item in batch]\n\n    return {'pet_ids': pet_ids, 'text_inputs': text_inputs, 'images': images, 'labels': labels}","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.898746Z","iopub.execute_input":"2024-12-23T17:22:21.898956Z","iopub.status.idle":"2024-12-23T17:22:21.914552Z","shell.execute_reply.started":"2024-12-23T17:22:21.898938Z","shell.execute_reply":"2024-12-23T17:22:21.913845Z"},"trusted":true},"outputs":[],"execution_count":87},{"cell_type":"markdown","source":"Let`s determine a way we will transform our images before the learning:","metadata":{}},{"cell_type":"code","source":"# Transform\ntransform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.915770Z","iopub.execute_input":"2024-12-23T17:22:21.916072Z","iopub.status.idle":"2024-12-23T17:22:21.932240Z","shell.execute_reply.started":"2024-12-23T17:22:21.916046Z","shell.execute_reply":"2024-12-23T17:22:21.931522Z"},"trusted":true},"outputs":[],"execution_count":88},{"cell_type":"markdown","source":"Creating datasets and dataloaders:","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import random_split, DataLoader\n\ntrain_size = int(0.8 * len(balanced_train_df))\nval_size = len(balanced_train_df) - train_size\n\ntrain_indices, val_indices = random_split(range(len(balanced_train_df)), [train_size, val_size])\n\ntrain_df = balanced_train_df.iloc[train_indices.indices]\nval_df = balanced_train_df.iloc[val_indices.indices]\n\ntrain_dataset = PetDataset(train_df, images_dir, tokenizer, transform=transform)\nval_dataset = PetDataset(val_df, images_dir, tokenizer, transform=transform)\ntest_dataset = PetDataset(test_df, images_dir, tokenizer, transform=transform)\n\ntrain_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=custom_collate_fn)\nval_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)\ntest_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=custom_collate_fn)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.933146Z","iopub.execute_input":"2024-12-23T17:22:21.933365Z","iopub.status.idle":"2024-12-23T17:22:21.951870Z","shell.execute_reply.started":"2024-12-23T17:22:21.933347Z","shell.execute_reply":"2024-12-23T17:22:21.950964Z"},"trusted":true},"outputs":[],"execution_count":89},{"cell_type":"markdown","source":"## Model class and optuna","metadata":{}},{"cell_type":"markdown","source":"In this case we are going to use Resnet50 to process the images and BERT to process the text:","metadata":{}},{"cell_type":"code","source":"class PetModel(nn.Module):\n    def __init__(self):\n        super(PetModel, self).__init__()\n        self.text_model = BertModel.from_pretrained('bert-base-uncased')\n        self.image_model = models.resnet50(pretrained=True)\n        self.image_model.fc = nn.Identity()  # Remove classification head\n\n        self.fc = nn.Sequential(\n            nn.Linear(768 + 2048, 512),  # Combining text (768) and image (2048) features\n            nn.ReLU(),\n            nn.Dropout(0.5),\n            nn.Linear(512, 5),  # Output layer with 5 units (for 5 classes)\n            nn.Softmax(dim=1)    # Softmax activation on the output\n        )\n\n    def forward(self, text_inputs, images):\n        # Process text inputs\n        text_features = self.text_model(**text_inputs).pooler_output\n\n        # Process image inputs\n        batch_size, num_images, channels, height, width = images.size()\n        image_features = []\n\n        # Loop over each sample in the batch\n        for i in range(batch_size):\n            sample_images = images[i]  # Shape: (num_images, 3, 224, 224)\n            sample_features = []\n\n            # Loop over each image for the current sample\n            for j in range(num_images):\n                image = sample_images[j].unsqueeze(0)  # Shape: (1, 3, 224, 224)\n                feature = self.image_model(image)  # Feature shape: (1, 2048)\n                sample_features.append(feature)\n\n            # Stack the features and average them across images\n            sample_features = torch.stack(sample_features).mean(dim=0)  # Shape: (1, 2048)\n            image_features.append(sample_features)\n\n        # Stack all image features (shape: (batch_size, 2048))\n        image_features = torch.stack(image_features)  \n\n        # Flatten the text features (batch_size, 768) and image features (batch_size, 2048)\n        text_features = text_features.view(batch_size, -1)  # Ensure text features are 2D\n        image_features = image_features.view(batch_size, -1)  # Ensure image features are 2D\n\n        # Concatenate text and image features\n        combined_features = torch.cat((text_features, image_features), dim=1)\n\n        # Final classification layer with softmax\n        output = self.fc(combined_features)\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2024-12-23T17:22:21.952658Z","iopub.execute_input":"2024-12-23T17:22:21.952873Z","iopub.status.idle":"2024-12-23T17:22:21.961504Z","shell.execute_reply.started":"2024-12-23T17:22:21.952854Z","shell.execute_reply":"2024-12-23T17:22:21.960547Z"},"trusted":true},"outputs":[],"execution_count":90},{"cell_type":"markdown","source":"Let`s create an Optuna objective function:","metadata":{}},{"cell_type":"code","source":"def objective(trial):\n    # Hyperparameters for optimization\n    dropout_rate = trial.suggest_float('dropout_rate', 0.1, 0.5)\n    lr = trial.suggest_float('lr', 1e-5, 1e-3, log=True)\n    batch_size = trial.suggest_categorical('batch_size', [32, 64])\n\n    # Update DataLoader with new batch_size\n    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=custom_collate_fn, num_workers=4)\n    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, collate_fn=custom_collate_fn, num_workers=4)\n\n    # Initialize model\n    model = PetModel()\n    model = nn.DataParallel(model)  # Wrap for multi-GPU\n    model = model.to(device)\n    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-5)\n    criterion = nn.CrossEntropyLoss()\n\n    # Training loop for 3 epochs\n    num_epochs = 3\n    for epoch in range(num_epochs):\n        model.train()\n        for batch in train_loader:\n            input_ids = batch['text_inputs']['input_ids'].to(device)\n            attention_mask = batch['text_inputs']['attention_mask'].to(device)\n            images = batch['images'].to(device)\n            labels = batch['labels'].to(device)\n\n            optimizer.zero_grad()\n            outputs = model(\n                text_inputs={'input_ids': input_ids, 'attention_mask': attention_mask},\n                images=images\n            )\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n    # Validation\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for batch in val_loader:\n            input_ids = batc8device)\n\n            outputs = model(\n                text_inputs={'input_ids': input_ids, 'attention_mask': attention_mask},\n                images=images\n            )\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            all_preds.extend(preds)\n            all_labels.extend(labels.cpu().numpy())\n\n    val_kappa = cohen_kappa_score(all_labels, all_preds, weights='quadratic')\n    return val_kappa\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T17:25:04.048361Z","iopub.execute_input":"2024-12-23T17:25:04.048681Z","iopub.status.idle":"2024-12-23T17:25:04.057664Z","shell.execute_reply.started":"2024-12-23T17:25:04.048657Z","shell.execute_reply":"2024-12-23T17:25:04.056614Z"}},"outputs":[],"execution_count":93},{"cell_type":"markdown","source":"And a study:","metadata":{}},{"cell_type":"code","source":"study = optuna.create_study(direction='maximize')\nstudy.optimize(objective, n_trials=10)\n\nprint('Найкраще значення Kappa:', study.best_value)\nprint('Найкращі гіперпараметри:')\nfor key, value in study.best_params.items():\n    print(f'    {key}: {value}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T17:25:07.094306Z","iopub.execute_input":"2024-12-23T17:25:07.094615Z","iopub.status.idle":"2024-12-23T18:55:59.042697Z","shell.execute_reply.started":"2024-12-23T17:25:07.094591Z","shell.execute_reply":"2024-12-23T18:55:59.041974Z"}},"outputs":[{"name":"stderr","text":"[I 2024-12-23 17:25:07,096] A new study created in memory with name: no-name-b38254cc-94d5-4e8a-a560-8963af689f0c\n[I 2024-12-23 17:34:10,252] Trial 0 finished with value: 0.23752293442274786 and parameters: {'dropout_rate': 0.4391976263774061, 'lr': 7.694906509391704e-05, 'batch_size': 64}. Best is trial 0 with value: 0.23752293442274786.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 17:43:10,624] Trial 1 finished with value: 0.4675050788585333 and parameters: {'dropout_rate': 0.20981693394453257, 'lr': 3.85392872666055e-05, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 17:52:05,332] Trial 2 finished with value: 0.0 and parameters: {'dropout_rate': 0.2502427679044994, 'lr': 0.0009360564909188658, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:01:01,443] Trial 3 finished with value: 0.19545676841874682 and parameters: {'dropout_rate': 0.4539803826193035, 'lr': 2.4590587389685526e-05, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:10:00,985] Trial 4 finished with value: 0.26424310875133405 and parameters: {'dropout_rate': 0.10547317991464614, 'lr': 1.5212497301427801e-05, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:19:28,399] Trial 5 finished with value: 0.0 and parameters: {'dropout_rate': 0.22410333371611926, 'lr': 0.0008752295891070546, 'batch_size': 32}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:28:19,846] Trial 6 finished with value: 0.0 and parameters: {'dropout_rate': 0.41947593065930233, 'lr': 0.0006778650600430217, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:37:42,687] Trial 7 finished with value: 0.0 and parameters: {'dropout_rate': 0.22835352986979252, 'lr': 0.000706059587701047, 'batch_size': 32}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:47:05,087] Trial 8 finished with value: 0.0 and parameters: {'dropout_rate': 0.37674424125759887, 'lr': 0.0004602736116164956, 'batch_size': 32}. Best is trial 1 with value: 0.4675050788585333.\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n[I 2024-12-23 18:55:59,036] Trial 9 finished with value: 0.0 and parameters: {'dropout_rate': 0.18866802284832285, 'lr': 0.0005928819868565561, 'batch_size': 64}. Best is trial 1 with value: 0.4675050788585333.\n","output_type":"stream"},{"name":"stdout","text":"Найкраще значення Kappa: 0.4675050788585333\nНайкращі гіперпараметри:\n    dropout_rate: 0.20981693394453257\n    lr: 3.85392872666055e-05\n    batch_size: 64\n","output_type":"stream"}],"execution_count":94},{"cell_type":"markdown","source":"## Training and evaluation","metadata":{}},{"cell_type":"markdown","source":"Now that we have the best model parameters for training, let`s determine a function to train and evaluate our model:","metadata":{}},{"cell_type":"code","source":"# Training and evaluation functions\ndef train_one_epoch(model, loader, optimizer, criterion):\n    model.train()\n    total_loss = 0\n    for batch in tqdm(loader, desc=\"Training\", leave=False):\n        text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n        images = batch['images'].to(device)\n        labels = batch['label'].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(text_inputs, images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        total_loss += loss.item()\n\n    return total_loss / len(loader)\n\ndef evaluate(model, loader, criterion):\n    model.eval()\n    total_loss = 0\n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Evaluating\", leave=False):\n            text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n            images = batch['images'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(text_inputs, images)\n            loss = criterion(outputs, labels)\n\n            total_loss += loss.item()\n\n    return total_loss / len(loader)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-12-23T19:00:51.917393Z","iopub.execute_input":"2024-12-23T19:00:51.917675Z","iopub.status.idle":"2024-12-23T19:00:51.924542Z","shell.execute_reply.started":"2024-12-23T19:00:51.917654Z","shell.execute_reply":"2024-12-23T19:00:51.923760Z"},"trusted":true},"outputs":[],"execution_count":101},{"cell_type":"markdown","source":"Creating new dataloaders with new batch_size and starting the training:","metadata":{}},{"cell_type":"code","source":"best_params = study.best_params\nbatch_size = best_params['batch_size']\ndropout_rate = best_params['dropout_rate']\nlearning_rate = best_params['lr']\n\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\nmodel = PetModel() \nmodel = nn.DataParallel(model)\nmodel = model.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\ncriterion = nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T18:57:52.920201Z","iopub.execute_input":"2024-12-23T18:57:52.920535Z","iopub.status.idle":"2024-12-23T18:57:53.776369Z","shell.execute_reply.started":"2024-12-23T18:57:52.920508Z","shell.execute_reply":"2024-12-23T18:57:53.775346Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"num_epochs = 15\nfor epoch in range(num_epochs):\n    train_loss = train_one_epoch(model, train_loader, optimizer, criterion)\n    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-12-23T19:00:57.058456Z","iopub.execute_input":"2024-12-23T19:00:57.058735Z","iopub.status.idle":"2024-12-23T19:44:52.827142Z","shell.execute_reply.started":"2024-12-23T19:00:57.058714Z","shell.execute_reply":"2024-12-23T19:44:52.825813Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15, Train Loss: 1.5722\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/15, Train Loss: 1.5284\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/15, Train Loss: 1.4339\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/15, Train Loss: 1.3443\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/15, Train Loss: 1.2584\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/15, Train Loss: 1.1928\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/15, Train Loss: 1.1467\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/15, Train Loss: 1.1155\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/15, Train Loss: 1.0835\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/15, Train Loss: 1.0717\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/15, Train Loss: 1.0523\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/15, Train Loss: 1.0392\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/15, Train Loss: 1.0400\n","output_type":"stream"},{"name":"stderr","text":"                                                           \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/15, Train Loss: 1.0266\n","output_type":"stream"},{"name":"stderr","text":"                                                           ","output_type":"stream"},{"name":"stdout","text":"Epoch 15/15, Train Loss: 1.0151\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":103},{"cell_type":"markdown","source":"In this notebook we will use some functions to evaluate our model with quadratic_weighted_kappa:","metadata":{}},{"cell_type":"code","source":"# The following 3 functions have been taken from Ben Hamner's github repository\n# https://github.com/benhamner/Metrics\ndef confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(rater_a + rater_b)\n    if max_rating is None:\n        max_rating = max(rater_a + rater_b)\n    num_ratings = int(max_rating - min_rating + 1)\n    conf_mat = [[0 for i in range(num_ratings)]\n                for j in range(num_ratings)]\n    for a, b in zip(rater_a, rater_b):\n        conf_mat[a - min_rating][b - min_rating] += 1\n    return conf_mat\n\n\ndef histogram(ratings, min_rating=None, max_rating=None):\n    if min_rating is None:\n        min_rating = min(ratings)\n    if max_rating is None:\n        max_rating = max(ratings)\n    num_ratings = int(max_rating - min_rating + 1)\n    hist_ratings = [0 for x in range(num_ratings)]\n    for r in ratings:\n        hist_ratings[r - min_rating] += 1\n    return hist_ratings\n\n\ndef quadratic_weighted_kappa(y, y_pred):\n    rater_a = y\n    rater_b = y_pred\n    min_rating=None\n    max_rating=None\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return (1.0 - numerator / denominator)","metadata":{"execution":{"iopub.status.busy":"2024-12-23T19:44:55.149402Z","iopub.execute_input":"2024-12-23T19:44:55.149735Z","iopub.status.idle":"2024-12-23T19:44:55.161806Z","shell.execute_reply.started":"2024-12-23T19:44:55.149702Z","shell.execute_reply":"2024-12-23T19:44:55.160835Z"},"trusted":true},"outputs":[],"execution_count":104},{"cell_type":"markdown","source":"Let`s validate the model!","metadata":{}},{"cell_type":"code","source":"from tqdm import tqdm\nimport numpy as np\nimport torch\n\ndef validate_model(model, loader, criterion, device):\n    model.eval()\n    total_loss = 0\n    all_targets = []\n    all_predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Validating\", leave=False):\n            text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n            images = batch['images'].to(device)\n            labels = batch['label'].to(device)\n\n            outputs = model(text_inputs, images)\n\n            loss = criterion(outputs, labels)\n            total_loss += loss.item()\n\n            all_targets.extend(labels.cpu().numpy())\n            all_predictions.extend(outputs.argmax(dim=1).cpu().numpy())\n\n    avg_loss = total_loss / len(loader)\n\n    conf_mat = confusion_matrix(all_targets, all_predictions)\n    print(\"\\nConfusion Matrix:\")\n    for row in conf_mat:\n        print(row)\n\n    hist_targets = histogram(all_targets)\n    hist_predictions = histogram(all_predictions)\n    print(\"\\nHistogram of Targets:\", hist_targets)\n    print(\"Histogram of Predictions:\", hist_predictions)\n\n    kappa_score = quadratic_weighted_kappa(all_targets, all_predictions)\n\n    return avg_loss, kappa_score\n\nval_loss, val_kappa = validate_model(model, val_loader, criterion, device)\nprint(f\"\\nValidation Loss: {val_loss:.4f}\")\nprint(f\"Kappa Score: {val_kappa:.4f}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-12-23T19:45:10.493990Z","iopub.execute_input":"2024-12-23T19:45:10.494297Z","iopub.status.idle":"2024-12-23T19:45:26.456421Z","shell.execute_reply.started":"2024-12-23T19:45:10.494273Z","shell.execute_reply":"2024-12-23T19:45:26.455447Z"},"trusted":true},"outputs":[{"name":"stderr","text":"                                                           ","output_type":"stream"},{"name":"stdout","text":"\nConfusion Matrix:\n[329, 43, 13, 27]\n[66, 291, 34, 51]\n[33, 46, 286, 45]\n[49, 51, 26, 317]\n\nHistogram of Targets: [412, 442, 410, 443]\nHistogram of Predictions: [477, 431, 359, 440]\n\nValidation Loss: 1.1878\nKappa Score: 0.6510\n","output_type":"stream"},{"name":"stderr","text":"\r","output_type":"stream"}],"execution_count":106},{"cell_type":"markdown","source":"## Saving the predictions","metadata":{}},{"cell_type":"markdown","source":"And save the predictions to submit:","metadata":{}},{"cell_type":"code","source":"def save_predictions(model, loader, device, output_csv):\n    model.eval()\n    pet_ids = []\n    predictions = []\n    \n    with torch.no_grad():\n        for batch in tqdm(loader, desc=\"Predicting\"):\n            # Move data to device\n            text_inputs = {key: val.to(device) for key, val in batch['text_inputs'].items()}\n            images = batch['images'].to(device)\n\n            # Get predictions\n            outputs = model(text_inputs, images)\n            preds = outputs.argmax(dim=1).cpu().numpy()  # Predicted classes\n\n            pet_ids.extend(batch['pet_id'])\n            predictions.extend(preds)\n\n    # Save to CSV\n    prediction_df = pd.DataFrame({'PetID': pet_ids, 'AdoptionSpeed': predictions})\n    prediction_df.to_csv(output_csv, index=False)\n    print(f\"Predictions saved to {output_csv}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T20:02:56.290412Z","iopub.execute_input":"2024-12-23T20:02:56.290709Z","iopub.status.idle":"2024-12-23T20:02:56.296712Z","shell.execute_reply.started":"2024-12-23T20:02:56.290683Z","shell.execute_reply":"2024-12-23T20:02:56.295996Z"}},"outputs":[],"execution_count":112},{"cell_type":"code","source":"test_output_csv = \"test_predictions.csv\"\nsave_predictions(model, test_loader, device, test_output_csv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T20:02:58.269846Z","iopub.execute_input":"2024-12-23T20:02:58.270169Z","iopub.status.idle":"2024-12-23T20:03:16.316460Z","shell.execute_reply.started":"2024-12-23T20:02:58.270130Z","shell.execute_reply":"2024-12-23T20:03:16.315454Z"}},"outputs":[{"name":"stderr","text":"Predicting: 100%|██████████| 30/30 [00:18<00:00,  1.66it/s]","output_type":"stream"},{"name":"stdout","text":"Predictions saved to test_predictions.csv\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":113}]}